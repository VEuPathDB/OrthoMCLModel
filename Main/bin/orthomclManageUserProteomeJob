#!/usr/bin/perl

use lib "$ENV{GUS_HOME}/lib/perl";
use File::Path;
use File::Copy;
use GUS::Workflow::SshCluster;
use OrthoMCLData::Load::ProteomeJobMgr;
use Digest::MD5 qw(md5_hex);

use strict;

=pod 

probe the state of orthomcl user's proteome analysis jobs

should be called by cron once every few minutes

** local dir structure **
controlDir/
  newJobs/
    92hty2k/
      info.txt
      proteome.fasta
  phase1/
    runningJobs/
      i83j89/
        info.txt
        input/
          controller.prop
          task.prop
        proteome.fasta
    doneJobs/
      43k8sl0/
        blastSimilarity.out
        info.txt
        input/
          controller.prop
          task.prop
        proteome.fasta
    failedJobs/
      a7bbe32/                (copied from runningJobs/)
  phase2/                     (same as phase1)


** cluster dir structure **
orthomclUserProteomeJobs/
  phase1/
    runningJobs/
      i83j89/
        info.txt
        input/
          controller.prop
          task.prop
        master/
          completedSubtasks.log
          failures/
          mainresult/
          running/
        i83j89.log
        processId
        proteome.fasta
    failedJobs/
      i83j89/        (copied from runningJobs/)
      i83j89.log     (copied from runningJobs/)
  phase2/            (same as phase1)


** info.txt file **
email=
fastaFileName=
submitted=
jobName=

=cut

usage() unless scalar(@ARGV) == 1;

my $configFile = $ARGV[0];

my $controlDir;
my $clusterServerDir;
my $dbSize;
my $fakeTaxonAbbrev = 'xxxx';

my $mgr = OrthoMCLData::Load::ProteomeJobMgr->new($configFile);

eval {
    $controlDir = $mgr->getConfig('controlDir');
    $clusterServerDir = $mgr->getConfig('clusterServerDir');

    # phase 1 (self-self blast of user proteome)
    my ($doneJobs, $failedJobs) = checkRunningJobs('phase1');

    handleDoneJobs($doneJobs, 'phase1');

    handleFailedJobs($failedJobs, 'phase1');

    handleNewJobs("$controlDir/newJobs",
		  "$controlDir/phase1/runningJobs",
		  "$clusterServerDir/phase1/runningJobs",
		  'phase1', $dbSize);

    # phase 2 (blast of user proteome against orthomcl proteins)

    my ($doneJobs, $failedJobs) = checkRunningJobs('phase2');

    handleDoneJobs($doneJobs, 'phase2');

    handleFailedJobs($failedJobs, 'phase2');

    handleNewJobs("$controlDir/phase1/doneJobs",
		  "$controlDir/phase2/runningJobs",
		  "$clusterServerDir/phase2/runningJobs",
		  'phase2', $dbSize);

    # deliver results (process blast results, and deliver results to user)
    # for each phase 2 done job, process it, and delete when done
    deliverResults();
};

$mgr->error("error: '$@'") if $@;


sub findDbSize {
    my ($localRunningDir, $clusterRunningDir) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $dbFilePath = $mgr->getConfig('blastDbFilePath');

    $mgr->log("Counting proteins in $dbFilePath");

    # discover size of blast db (ie, count of orthomcl proteins)
    my $dbSizeOut = $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"grep \\> $dbFilePath |wc -l\"'");
    my @a = split(/\s/, $dbSizeOut);  # ignore output from login
    my $dbSize = $a[$#a];
    return $dbSize;
}

##################################################
# handle running jobs
##################################################

sub checkRunningJobs {
    my ($phase) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');

    my $runningJobsDir = "$controlDir/$phase/runningJobs";
    mkpath($runningJobsDir);
    opendir(DIR, $runningJobsDir) || die "Can't open $phase runningJobs/ directory '$runningJobsDir'\n";
    my @runningJobs = readdir(DIR);
    closedir(DIR);

    my $doneJobs;
    my $failedJobs;
    foreach my $runningJob (@runningJobs) {
	next if $runningJob =~ /^\./;
	my $clusterRunningJobDir = "$clusterServerDir/$phase/runningJobs/$runningJob";
	if (!clusterTaskRunning($clusterRunningJobDir, $clusterUserName, $clusterServer)) {
	  $mgr->log("Found $phase job that has finished running: $runningJob");
	  my $logFile = "$clusterRunningJobDir/$runningJob.log";
	  my $done = $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"if [ -a $logFile ]; then tail -1 $logFile; fi\"'");
	  if ($done && $done =~ /Done/) {
	    push(@$doneJobs, $runningJob);
	  } else {
	    push(@$failedJobs, $runningJob);
	  }
	}
      }

    return ($doneJobs, $failedJobs);
}

sub clusterTaskRunning {
    my ($clusterJobDir, $clusterUserName, $clusterServer) = @_;

    my $processId = `ssh -2 $clusterUserName\@$clusterServer 'if [ -a $clusterJobDir/processId ];then cat $clusterJobDir/processId; fi'`;

    chomp $processId;

    my $status = 0;
    if ($processId) {
      system("ssh -2 $clusterUserName\@$clusterServer 'ps -p $processId > /dev/null'");
      $status = $? >> 8;
      $status = !$status;
    }
    return $status;
}


##################################################
# handle completed jobs
##################################################
sub handleDoneJobs {
    my ($doneJobs, $phase) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $localRunningDir = "$controlDir/$phase/runningJobs";
    my $localDoneDir = "$controlDir/$phase/doneJobs";

    foreach my $doneJob (@$doneJobs) {

      $mgr->log("Handling done $phase cluster job: $doneJob");
      mkpath($localDoneDir);
      move("$localRunningDir/$doneJob", "$localDoneDir/$doneJob");

      # zip blast result
      $mgr->log("  gzipping blast result on cluster");
      my $clusterRunningJobDir = "$clusterServerDir/$phase/runningJobs/$doneJob";
      $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"gzip $clusterRunningJobDir/master/mainresult/blastSimilarity.out\"'");

      # copy result from cluster
      $mgr->log("  copying from cluster");
      $mgr->getCluster()->copyFrom("$clusterRunningJobDir/master/mainresult", 'blastSimilarity.out.gz', "$localDoneDir/$doneJob");
      move("$localDoneDir/$doneJob/blastSimilarity.out.gz", "$localDoneDir/$doneJob/${phase}BlastSimilarity.out.gz");


      # clean up cluster dir
      $mgr->log("  cleaning up cluster job dir");
      $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"rm -rf $clusterRunningJobDir\"'");

    }
}

sub deliverResults {

    my $phase2DoneDir = "$controlDir/phase2/doneJobs";
    opendir(DIR, $phase2DoneDir) || die "Can't open phase2 doneJobs/ directory '$phase2DoneDir'\n";
    my @donePhase2Jobs = readdir(DIR);
    closedir(DIR);

    foreach my $phase2DoneJob (@donePhase2Jobs) {
      next if $phase2DoneJob =~ /^\./;
      $mgr->log("Final processing for $phase2DoneJob");
      deliverResult("$controlDir/phase2/doneJobs/$phase2DoneJob", $phase2DoneJob);
      $mgr->log("  cleaning up local phase2 job dir");
      rmtree("$controlDir/phase2/doneJobs/$phase2DoneJob");
    }
}

sub deliverResult {
    my ($donePhase2JobDir, $jobId) = @_;

    my $groupsFile = $mgr->getConfig('groupsFile');
    my $mclBin = $mgr->getConfig('mclBin');
    my $resultDir = $mgr->getConfig('resultDir');

    # map to groups
    $mgr->log("  mapping to groups");
    mkpath("$donePhase2JobDir/orthomclResult");
    my $cmd = "orthomclMapProteomeToGroups $donePhase2JobDir/phase1BlastSimilarity.out.gz $donePhase2JobDir/phase2BlastSimilarity.out.gz $groupsFile $fakeTaxonAbbrev $donePhase2JobDir/orthomclResult $mclBin $donePhase2JobDir/log";
    $mgr->log("  $cmd");
    $mgr->runCmd(0, $cmd);
    open(L, "$donePhase2JobDir/log");
    while(<L>) {print STDERR $_;}
    close(L);

    # zip result
    copy("$donePhase2JobDir/info.txt", "$donePhase2JobDir/orthomclResult");
    $mgr->log("  zipping");
    $mgr->runCmd(0, "zip -rj $donePhase2JobDir/orthomclResult $donePhase2JobDir/orthomclResult");

    # move zipped result to delivery dir
    move("$donePhase2JobDir/orthomclResult.zip", "$resultDir/orthomclResult-$jobId.zip");

    # email result
    $mgr->log("  mailing notification");
    mailResult("$donePhase2JobDir/info.txt", $jobId);
}


##################################################
# handle new jobs
##################################################
sub handleNewJobs {
    my ($newJobsDir, $localRunningDir, $clusterRunningDir, $phase) = @_;

    # find all subdirs 
    opendir(DIR, $newJobsDir) || die "Can't open $phase new jobs directory '$newJobsDir'\n";
    my @newJobs = readdir(DIR);
    closedir(DIR);

    foreach my $newJob (@newJobs) {
	next if $newJob =~ /^\./;
	$mgr->log("New $phase job: $newJob");

	my $clusterUserName = $mgr->getConfig('clusterUserName');
	my $clusterServer = $mgr->getConfig('clusterServer');
	my $newJobDir = "$newJobsDir/$newJob";
	my $runningJobDir = "$localRunningDir/$newJob";
	my $localInputDir = "$runningJobDir/input";
	my $masterDir = "$runningJobDir/master";
	my $clusterRunningJobDir = "$clusterRunningDir/$newJob";
	my $clusterInputDir = "$clusterRunningJobDir/input";

	if ($phase eq 'phase1') {
	    if (validateProteomeFile("$newJobDir/orig_proteome.fasta")) {
		mailSubmit("$newJobDir/info.txt", $newJob);
	    } else {
	        $mgr->log("  invalid fasta");
		mailInvalidFasta("$newJobDir/info.txt", $newJob);
		rmtree($newJobDir);
		next;
	    }
	}

	# discover size of orthomcl blast database
	$dbSize = findDbSize() unless $dbSize;

	correctProteomeFile("$newJobDir/orig_proteome.fasta", "$newJobDir/proteome.fasta");

        # move new job dir to running/
	mkpath($runningJobDir);
	move("$newJobsDir/$newJob", $runningJobDir);

	# move proteome file to localInputDir
	mkpath($localInputDir);
	#$move("$runningJobDir/proteome.fasta", $localInputDir);

	my $dbFilePath =  ($phase eq 'phase1')?
	  "$clusterRunningJobDir/proteome.fasta" :
	    $mgr->getConfig('blastDbFilePath');

	# build input/ dir
	makeTaskFile($localInputDir, $clusterInputDir, $clusterRunningJobDir, $dbFilePath, $dbSize);
	makeControllerFile($localInputDir, $clusterInputDir);

	# mirror job to cluster
	$mgr->log("Mirroring $newJob/ to cluster");
	$mgr->getCluster()->copyTo($localRunningDir, $newJob, $clusterRunningDir);

	if ($phase eq 'phase1') {
	    # format db
	    my $blastBinDir = $mgr->getConfig('blastBinDir');
	    my $cmd = "$blastBinDir/formatdb -i $dbFilePath -p T";
	    $mgr->log("Formatting proteome.fasta for self-self blast");
	    $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"$cmd\"'");
	}

	# start cluster job
	startJob("$clusterRunningJobDir", $newJob);
    }

}

sub validateProteomeFile {
    my ($proteomeFile) = @_;
    my $length;
    my $seqCount;
    open(P, $proteomeFile) || die "\n";
    while(<P>) {
	$length += length($_);
	$seqCount += 1 if /^\>\S+/;
    }
    close(P);
    return ($seqCount && $seqCount <= 100000 && $length <= $seqCount * 1000);
}

sub correctProteomeFile {
    my ($orig_proteomeFile, $proteomeFile) = @_;

    open(O, $orig_proteomeFile) || die "can't open file $orig_proteomeFile";
    open(N, ">$proteomeFile") || die "can't open file $proteomeFile for writing";
    while (<O>) {
	s/\>/\>$fakeTaxonAbbrev\|/ if (/\>/);
	print N $_;
    }
    close(O);
    close(N);
}

sub makeTaskFile {
    my ($localInputDir, $clusterInputDir, $clusterRunningJobDir, $dbFilePath, $dbSize) = @_;
      open(F, ">$localInputDir/task.prop") || die "Can't open task prop file '$localInputDir/task.prop' for writing";

    my $blastBinDir = $mgr->getConfig('blastBinDir');
    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');

    print F
"blastBinDir=$blastBinDir
dbFilePath=$dbFilePath
inputFilePath=$clusterRunningJobDir/proteome.fasta
dbType=p
regex='(\\S+)'
blastProgram=blastp
blastParamsFile=blastParams
blastVendor=ncbi
printSimSeqsFile=yes
";
    close(F);

    # make blastParams file
    my $blastArgs = $mgr->getConfig('blastArgs');
    die "error: do not include -z arg in blastArgs property.  it is discovered dynamically" if $blastArgs =~ /z/;
    open(F, ">$localInputDir/blastParams") || die "Can't open blast params file '$localInputDir/blastParams' for writing";;
    print F "$blastArgs -z $dbSize\n";
    close(F);
}

sub makeControllerFile {
    my ($localInputDir, $clusterInputDir) = @_;
  my ($self, $taskInputDir, $slotsPerNode, $taskSize, $taskClass) = @_;

  my $nodePath = $mgr->getConfig('nodePath');
  my $slotsPerNode = $mgr->getConfig('slotsPerNode');
  my $nodeClass = $mgr->getConfig('nodeClass');
  my $taskSize = $mgr->getConfig('taskSize');
  my $taskClass = $mgr->getConfig('taskClass');
  my $nodeClass = $mgr->getConfig('nodeClass');

  my $clusterMasterDir = $clusterInputDir;
  $clusterMasterDir =~ s/input/master/;
  $nodeClass = 'DJob::DistribJob::BprocNode' unless $nodeClass;

  # print out the file
  my $controllerPropFile = "$localInputDir/controller.prop";
  open(F, ">$controllerPropFile")
      || $self->error("Can't open controller prop file '$controllerPropFile' for writing");
  print F 
"masterdir=$clusterMasterDir
inputdir=$clusterInputDir
nodedir=$nodePath
slotspernode=$slotsPerNode
subtasksize=$taskSize
taskclass=$taskClass
nodeclass=$nodeClass
restart=no
";
    close(F);
}

sub startJob {
    my ($clusterJobDir, $jobId) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $numNodes = $mgr->getConfig('numNodes');
    my $clusterQueue = $mgr->getConfig('clusterQueue');
    my $ppn = $mgr->getConfig('ppn');

    $mgr->log("Starting job on cluster in $clusterJobDir");
    $mgr->runClusterTask($clusterUserName, $clusterServer, "$clusterJobDir/processId", "$clusterJobDir/$jobId.log", "$clusterJobDir/input/controller.prop", $numNodes, 14400, $clusterQueue, $ppn);
}


##################################################
# handle failed jobs
##################################################
sub handleFailedJobs {
    my ($failedJobs, $phase) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $localRunningDir = "$controlDir/$phase/runningJobs";
    my $localFailedDir = "$controlDir/$phase/failedJobs";

    foreach my $failedJob (@$failedJobs) {

      $mgr->log("Handling $phase failed job: $failedJob");
      mkpath("$localRunningDir/$failedJob");
      move("$localRunningDir/$failedJob", "$localFailedDir/$failedJob");

      # clean up cluster dir
      $mgr->log("  moving cluster job to failed dir");
      my $clusterRunningJobDir = "$clusterServerDir/$phase/runningJobs/$failedJob";
      $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"mv $clusterRunningJobDir $clusterServerDir/$phase/failedJobs\"'");
    }
}

sub mailSubmit {
  my ($infoFile, $jobId) = @_;

  my $msg = "
has been submitted.  You will get a mail when it is done (6 to 24 hours).
";
  mailJob($infoFile, $jobId, "OrthoMCL Job - submitted", $msg);
}

sub mailInvalidFasta {
  my ($infoFile, $jobId) = @_;

  my $msg = "
has an invalid sequence file.  The file must be in Fasta format and contain no more than 100,000 protein sequences.  Please resubmit with a valid file.
";
  mailJob($infoFile, $jobId, "OrthoMCL Job - invalid file", $msg);
}

sub mailResult {
  my ($infoFile, $jobId) = @_;

  my $baseUrl = $mgr->getConfig('resultBaseUrl');
  my $link = "$baseUrl$jobId";

  my $msg = "
is complete.  The results are now available at:
  $link

They will be available for 48 hours.
";
  mailJob($infoFile, $jobId, "OrthoMCL Job - done", $msg);
}

sub mailJob {
  my ($infoFile, $jobId, $subject, $message) = @_;

  open(I, $infoFile) || die "Can't open info file '$infoFile'";
  my $info;
  while (<I>) {
    chomp;
    my($key, $value) = split(/\=/);
    $info->{$key} = $value;
  }
  close(I);
  $info->{email} =~ /^[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,4}$/i or die "Illegal email address: '$info->{email}'\n";

  my @a = split(/\@/, $info->{email});
  my $login = shift(@a);

  my $body = "
Hello $login,

Your OrthoMCL job:
  ID:         $jobId
  Name:       $info->{jobName}
  Fasta file: $info->{fastaFileName}
  Submitted:  $info->{submitted}
$message
Thank you for using OrthoMCL,
The OrthoMCL Team
";

  open(SENDMAIL, "|/usr/sbin/sendmail -t") or die "Cannot open sendmail: $!";
  print SENDMAIL "Subject: $subject\n";
  print SENDMAIL "To: $info->{email}\n";
  print SENDMAIL "From: help\@orthomcl.org\n";
  print SENDMAIL "Content-type: text/plain\n\n";
  print SENDMAIL $body;
  close(SENDMAIL);
}

sub usage {
  print STDERR "

usage:
   orthomclManageUserProteomeJob config_file

** config file **
blastDbFilePath= (blast database file)
groupsFile=           (orthomcl groups to map blast results to)
controlDir=           (local dir to control this job)
clusterUserName=      (login to use to get into cluster server)
clusterServer=        (name of machine)
clusterServerDir=     (dir there to put our stuff in)
clusterQueue=         (queue to use)
numNodes=             (num of nodes to request)
slotsPerNode=         (slots per each node)
ppn=                  (parallelization)
nodePath=             (???)
nodeClass=            (perl class to represent this type of node)
taskSize=             (number of seqs to process in one batch)
taskClass=            (perl class to manage that processing)
blastArgs=            (arguments for blast)
blastBinDir=          (location of blast executable)
mclBin=               (location of mcl executable)
resultDir             (dir to write result zip file to)
resultBaseUrl=          (URL to append job key to)
";

exit(1);

}


